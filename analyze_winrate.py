#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æå›æµ‹ç»“æœèƒœç‡ - å¤šç»´åº¦ç»Ÿè®¡

åˆ†æç»´åº¦ï¼š
1. DTEï¼ˆåˆ°æœŸå¤©æ•°ï¼‰
2. OTMæ¯”ä¾‹
3. äº¤æ˜“æ—¶é—´æ®µ
4. æœŸæƒshare_eqv
5. ä¹°å…¥å½“æ—¥æˆäº¤é‡

Usage:
    python analyze_winrate.py
"""

import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import pytz
from typing import Dict, List, Optional
import os
from collections import defaultdict

# Polygon APIé…ç½®
POLYGON_API_KEY = os.environ.get('POLYGON_API_KEY', 'YOUR_API_KEY')

def load_backtest_results(json_file: str) -> Dict:
    """åŠ è½½å›æµ‹ç»“æœJSON"""
    print(f"ğŸ“– åŠ è½½å›æµ‹ç»“æœ: {json_file}")
    with open(json_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data

def load_signal_csv(csv_file: str) -> pd.DataFrame:
    """åŠ è½½ä¿¡å·CSVæ•°æ®"""
    print(f"ğŸ“– åŠ è½½ä¿¡å·æ•°æ®: {csv_file}")
    df = pd.read_csv(csv_file)
    
    # è§£ææ—¥æœŸæ—¶é—´ï¼ˆCSVæ˜¯ä¸Šæµ·æ—¶é—´ï¼Œéœ€è¦è½¬æˆçº½çº¦æ—¶é—´ï¼‰
    df['datetime_shanghai'] = pd.to_datetime(df['date'] + ' ' + df['time'])
    df['datetime_shanghai'] = df['datetime_shanghai'].dt.tz_localize('Asia/Shanghai')
    
    # è½¬æ¢ä¸ºçº½çº¦æ—¶é—´
    df['datetime'] = df['datetime_shanghai'].dt.tz_convert('America/New_York')
    
    # è§£ædateä¸ºçº½çº¦æ—¶åŒºçš„æ—¥æœŸ
    df['date_ny'] = df['datetime'].dt.date
    
    # è®¡ç®—æ­£ç¡®çš„DTEï¼šexpiry - dateï¼ˆçº½çº¦æ—¶é—´ï¼‰
    df['expiry_date'] = pd.to_datetime(df['expiry'])
    df['dte_days'] = (df['expiry_date'] - pd.to_datetime(df['date_ny'])).dt.days
    
    # è§£æOTMç™¾åˆ†æ¯”
    df['otm_percent'] = df['otm_pct'].str.replace('%', '').astype(float)
    
    # è§£æshare_eqvï¼ˆå»æ‰é€—å·ï¼‰
    df['share_eqv_num'] = df['share_eqv'].str.replace(',', '').astype(float)
    
    # æå–äº¤æ˜“æ—¶é—´çš„å°æ—¶ï¼ˆçº½çº¦æ—¶é—´ï¼‰
    df['trade_hour'] = df['datetime'].dt.hour
    
    # è‚¡ä»·ï¼ˆspotåˆ—å·²ç»æ˜¯ç¾å…ƒæ ¼å¼ï¼‰
    df['stock_price'] = df['spot'].str.replace('$', '').astype(float)
    
    print(f"âœ… åŠ è½½äº† {len(df)} æ¡ä¿¡å·")
    print(f"   æ—¶åŒºè½¬æ¢: ä¸Šæµ·æ—¶é—´ â†’ çº½çº¦æ—¶é—´")
    print(f"   DTEèŒƒå›´: {df['dte_days'].min()}-{df['dte_days'].max()}å¤©")
    
    return df

def parse_trades(backtest_data: Dict) -> pd.DataFrame:
    """è§£æäº¤æ˜“è®°å½•ï¼ŒåŒ¹é…ä¹°å…¥å’Œå–å‡º"""
    trades = backtest_data['trades']
    
    # åˆ†ç¦»ä¹°å…¥å’Œå–å‡º
    buys = [t for t in trades if t['type'] == 'BUY']
    sells = [t for t in trades if t['type'] == 'SELL']
    
    print(f"ğŸ“Š ä¹°å…¥: {len(buys)} ç¬”, å–å‡º: {len(sells)} ç¬”")
    
    # æ„å»ºäº¤æ˜“å¯¹
    trade_pairs = []
    sell_dict = defaultdict(list)
    
    # æŒ‰symbolç»„ç»‡å–å‡ºè®°å½•
    for sell in sells:
        sell_dict[sell['symbol']].append(sell)
    
    # åŒ¹é…ä¹°å…¥å’Œå–å‡º
    for buy in buys:
        symbol = buy['symbol']
        buy_time = pd.to_datetime(buy['time'])
        
        # æŸ¥æ‰¾å¯¹åº”çš„å–å‡º
        matched_sell = None
        if symbol in sell_dict:
            for sell in sell_dict[symbol]:
                sell_time = pd.to_datetime(sell['time'])
                # å–å‡ºæ—¶é—´åº”è¯¥æ™šäºä¹°å…¥æ—¶é—´
                if sell_time > buy_time:
                    matched_sell = sell
                    sell_dict[symbol].remove(sell)  # ç§»é™¤å·²åŒ¹é…çš„
                    break
        
        # è®¡ç®—ç›ˆäº
        if matched_sell:
            pnl = matched_sell.get('profit', 0)
            pnl_pct = (matched_sell['price'] - buy['price']) / buy['price']
            win = pnl > 0
        else:
            # æœªåŒ¹é…åˆ°å–å‡ºï¼ˆå¯èƒ½è¿˜æŒä»“ï¼‰
            pnl = 0
            pnl_pct = 0
            win = None
        
        trade_pairs.append({
            'symbol': symbol,
            'buy_time': buy_time,
            'buy_price': buy['price'],
            'sell_time': pd.to_datetime(matched_sell['time']) if matched_sell else None,
            'sell_price': matched_sell['price'] if matched_sell else None,
            'pnl': pnl,
            'pnl_pct': pnl_pct,
            'win': win,
            'strike': buy.get('strike'),
            'expiry': buy.get('expiry'),
            'shares': buy.get('shares'),
            'position_ratio': buy.get('position_ratio')
        })
    
    df_trades = pd.DataFrame(trade_pairs)
    # åªä¿ç•™å·²å®Œæˆçš„äº¤æ˜“ï¼ˆæœ‰å–å‡ºçš„ï¼‰
    df_trades = df_trades[df_trades['win'].notna()].copy()
    
    print(f"âœ… åŒ¹é…äº† {len(df_trades)} ç¬”å®Œæ•´äº¤æ˜“")
    print(f"   èƒœç‡: {df_trades['win'].sum()}/{len(df_trades)} = {df_trades['win'].mean():.1%}")
    
    return df_trades

def match_trades_with_signals(df_trades: pd.DataFrame, df_signals: pd.DataFrame) -> pd.DataFrame:
    """å°†äº¤æ˜“è®°å½•ä¸ä¿¡å·æ•°æ®åŒ¹é…
    
    åŒ¹é…ç­–ç•¥ï¼š
    1. symbol + strike + expiry ç²¾ç¡®åŒ¹é…
    2. æ—¶é—´éªŒè¯ï¼šäº¤æ˜“æ—¶é—´ - 10åˆ†é’Ÿ â‰ˆ ä¿¡å·æ—¶é—´ï¼ˆè€ƒè™‘å»¶è¿Ÿï¼‰
    3. å¦‚æœæœ‰å¤šä¸ªåŒ¹é…ï¼Œé€‰æ‹©æ—¶é—´æœ€æ¥è¿‘çš„
    """
    print("ğŸ”— åŒ¹é…äº¤æ˜“è®°å½•ä¸ä¿¡å·æ•°æ®...")
    print("   åŒ¹é…é€»è¾‘: äº¤æ˜“æ—¶é—´ - 10åˆ†é’Ÿ â‰ˆ CSVä¿¡å·æ—¶é—´")
    
    matched_trades = []
    
    for idx, trade in df_trades.iterrows():
        trade_expiry = pd.to_datetime(trade['expiry'])
        
        # è®¡ç®—é¢„æœŸçš„ä¿¡å·æ—¶é—´ï¼ˆäº¤æ˜“æ—¶é—´ - 10åˆ†é’Ÿï¼‰
        expected_signal_time = trade['buy_time'] - timedelta(minutes=10)
        
        # æ–¹æ³•1ï¼šç²¾ç¡®åŒ¹é… symbol + strike + expiry
        matched_signals = df_signals[
            (df_signals['ticker'] == trade['symbol']) &
            (df_signals['strike'] == trade['strike']) &
            (df_signals['expiry_date'] == trade_expiry)
        ]
        
        if len(matched_signals) > 0:
            # æ–¹æ³•2ï¼šåœ¨åŒ¹é…ç»“æœä¸­ï¼Œæ‰¾æ—¶é—´æœ€æ¥è¿‘çš„ï¼ˆÂ±2åˆ†é’Ÿå®¹å·®ï¼‰
            matched_signals_copy = matched_signals.copy()
            matched_signals_copy['time_diff'] = (matched_signals_copy['datetime'] - expected_signal_time).abs()
            matched_signals_sorted = matched_signals_copy.sort_values('time_diff')
            
            # å–æ—¶é—´æœ€è¿‘çš„ä¿¡å·ï¼ˆé€šå¸¸åº”è¯¥åªæœ‰1ä¸ªï¼‰
            best_match = matched_signals_sorted.iloc[0]
            time_diff_minutes = best_match['time_diff'].total_seconds() / 60
            
            matched_trades.append({
                **trade.to_dict(),
                'dte': best_match['dte_days'],
                'otm_pct': best_match['otm_percent'],
                'trade_hour': best_match['trade_hour'],
                'share_eqv': best_match['share_eqv_num'],
                'stock_price': best_match['stock_price'],
                'date': best_match['date'],
                'signal_time': best_match['datetime'],
                'time_diff_min': time_diff_minutes
            })
        else:
            # æ²¡åŒ¹é…åˆ°ä¿¡å·
            matched_trades.append({
                **trade.to_dict(),
                'dte': None,
                'otm_pct': None,
                'trade_hour': None,
                'share_eqv': None,
                'stock_price': None,
                'date': None,
                'signal_time': None,
                'time_diff_min': None
            })
    
    df_matched = pd.DataFrame(matched_trades)
    matched_count = df_matched['dte'].notna().sum()
    total_count = len(df_matched)
    print(f"âœ… æˆåŠŸåŒ¹é… {matched_count}/{total_count} ç¬”äº¤æ˜“ ({matched_count/total_count:.1%})")
    
    # æ˜¾ç¤ºæ—¶é—´å·®ç»Ÿè®¡
    if matched_count > 0:
        avg_time_diff = df_matched['time_diff_min'].mean()
        max_time_diff = df_matched['time_diff_min'].max()
        print(f"   æ—¶é—´å·®: å¹³å‡{avg_time_diff:.1f}åˆ†é’Ÿ, æœ€å¤§{max_time_diff:.1f}åˆ†é’Ÿ")
    
    if matched_count < total_count * 0.5:
        print(f"âš ï¸  è­¦å‘Šï¼šåŒ¹é…ç‡ä½äº50%ï¼Œå¯èƒ½CSVæ•°æ®ä¸å®Œæ•´")
        print(f"   CSVæ—¥æœŸèŒƒå›´: {df_signals['date'].min()} åˆ° {df_signals['date'].max()}")
        print(f"   äº¤æ˜“æ—¥æœŸèŒƒå›´: {df_matched['buy_time'].min()} åˆ° {df_matched['buy_time'].max()}")
    
    return df_matched

def get_volume_from_polygon(symbol: str, date: str) -> Optional[float]:
    """ä»Polygon APIè·å–æŒ‡å®šæ—¥æœŸçš„æˆäº¤é‡
    
    Args:
        symbol: è‚¡ç¥¨ä»£ç 
        date: æ—¥æœŸ (YYYY-MM-DD)
    
    Returns:
        æˆäº¤é‡ï¼Œå¦‚æœè·å–å¤±è´¥è¿”å›None
    """
    try:
        import requests
        
        url = f"https://api.polygon.io/v1/open-close/{symbol}/{date}"
        params = {'apiKey': POLYGON_API_KEY, 'adjusted': 'true'}
        
        response = requests.get(url, params=params, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            return data.get('volume')
        else:
            return None
    except Exception as e:
        print(f"âš ï¸ è·å– {symbol} {date} æˆäº¤é‡å¤±è´¥: {e}")
        return None

def add_volume_data(df: pd.DataFrame, use_polygon: bool = False) -> pd.DataFrame:
    """æ·»åŠ æˆäº¤é‡æ•°æ®
    
    Args:
        df: äº¤æ˜“æ•°æ®DataFrame
        use_polygon: æ˜¯å¦ä½¿ç”¨Polygon APIè·å–æˆäº¤é‡ï¼ˆéœ€è¦API keyï¼‰
    
    Returns:
        æ·»åŠ äº†volumeåˆ—çš„DataFrame
    """
    if not use_polygon:
        print("â­ï¸ è·³è¿‡æˆäº¤é‡æ•°æ®è·å–ï¼ˆuse_polygon=Falseï¼‰")
        df['volume'] = None
        return df
    
    print("ğŸ“¡ ä»Polygonè·å–æˆäº¤é‡æ•°æ®...")
    
    volumes = []
    total = len(df)
    
    for idx, row in df.iterrows():
        if idx % 50 == 0:
            print(f"   è¿›åº¦: {idx}/{total} ({idx/total:.1%})")
        
        if pd.notna(row['date']) and pd.notna(row['symbol']):
            volume = get_volume_from_polygon(row['symbol'], row['date'])
            volumes.append(volume)
        else:
            volumes.append(None)
    
    df['volume'] = volumes
    print(f"âœ… è·å–äº† {pd.Series(volumes).notna().sum()}/{total} ä¸ªæˆäº¤é‡æ•°æ®")
    
    return df

def categorize_dte(dte):
    """DTEåˆ†ç±»"""
    if pd.isna(dte):
        return 'æœªçŸ¥'
    elif dte <= 7:
        return '0-7å¤©'
    elif dte <= 30:
        return '8-30å¤©'
    elif dte <= 60:
        return '31-60å¤©'
    elif dte <= 90:
        return '61-90å¤©'
    else:
        return '>90å¤©'

def categorize_otm(otm_pct):
    """OTMåˆ†ç±»"""
    if pd.isna(otm_pct):
        return 'æœªçŸ¥'
    elif otm_pct < 0:
        return 'ITM(<0%)'
    elif otm_pct <= 5:
        return 'ATM(0-5%)'
    elif otm_pct <= 10:
        return 'OTM(5-10%)'
    elif otm_pct <= 20:
        return 'OTM(10-20%)'
    else:
        return 'OTM(>20%)'

def categorize_time(hour):
    """äº¤æ˜“æ—¶é—´åˆ†ç±»"""
    if pd.isna(hour):
        return 'æœªçŸ¥'
    elif hour < 10:
        return 'å¼€ç›˜(9:30-10:00)'
    elif hour < 12:
        return 'ä¸Šåˆ(10:00-12:00)'
    elif hour < 14:
        return 'åˆå(12:00-14:00)'
    elif hour < 15:
        return 'å°¾ç›˜å‰(14:00-15:00)'
    else:
        return 'å°¾ç›˜(15:00-16:00)'

def categorize_share_eqv(share_eqv):
    """Share_eqvåˆ†ç±»ï¼ˆæµåŠ¨æ€§ï¼‰"""
    if pd.isna(share_eqv):
        return 'æœªçŸ¥'
    elif share_eqv < 10000:
        return '<1ä¸‡'
    elif share_eqv < 50000:
        return '1-5ä¸‡'
    elif share_eqv < 100000:
        return '5-10ä¸‡'
    elif share_eqv < 500000:
        return '10-50ä¸‡'
    else:
        return '>50ä¸‡'

def categorize_volume(volume):
    """æˆäº¤é‡åˆ†ç±»"""
    if pd.isna(volume):
        return 'æœªçŸ¥'
    elif volume < 1000000:
        return '<100ä¸‡'
    elif volume < 5000000:
        return '100-500ä¸‡'
    elif volume < 10000000:
        return '500-1000ä¸‡'
    else:
        return '>1000ä¸‡'

def analyze_by_dimension(df: pd.DataFrame, dimension: str, categorize_func) -> pd.DataFrame:
    """æŒ‰æŒ‡å®šç»´åº¦åˆ†æèƒœç‡"""
    df[f'{dimension}_cat'] = df[dimension].apply(categorize_func)
    
    stats = df.groupby(f'{dimension}_cat').agg({
        'win': ['count', 'sum', 'mean'],
        'pnl': 'sum',
        'pnl_pct': 'mean'
    }).round(4)
    
    stats.columns = ['äº¤æ˜“æ•°', 'èƒœåœº', 'èƒœç‡', 'æ€»ç›ˆäº', 'å¹³å‡ç›ˆäº%']
    stats['èƒœç‡'] = stats['èƒœç‡'].apply(lambda x: f"{x:.1%}")
    stats['å¹³å‡ç›ˆäº%'] = stats['å¹³å‡ç›ˆäº%'].apply(lambda x: f"{x:+.2%}")
    stats['æ€»ç›ˆäº'] = stats['æ€»ç›ˆäº'].apply(lambda x: f"${x:+,.0f}")
    
    return stats.sort_values('äº¤æ˜“æ•°', ascending=False)

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*80)
    print("ğŸ“Š å›æµ‹ç»“æœå¤šç»´åº¦èƒœç‡åˆ†æ")
    print("="*80 + "\n")
    
    # é…ç½®
    BACKTEST_FILE = 'backtest_v8_all.json'
    CSV_FILE = 'future_v_0_1/database/merged_strategy_v1_calls_bell_2023M3_2025M10.csv'
    USE_POLYGON = False  # æ˜¯å¦ä½¿ç”¨Polygonè·å–æˆäº¤é‡ï¼ˆéœ€è¦API keyï¼‰
    
    # 1. åŠ è½½æ•°æ®
    backtest_data = load_backtest_results(BACKTEST_FILE)
    df_signals = load_signal_csv(CSV_FILE)
    
    # 2. è§£æäº¤æ˜“è®°å½•
    df_trades = parse_trades(backtest_data)
    
    # 3. åŒ¹é…äº¤æ˜“ä¸ä¿¡å·
    df_matched = match_trades_with_signals(df_trades, df_signals)
    
    # 4. æ·»åŠ æˆäº¤é‡æ•°æ®ï¼ˆå¯é€‰ï¼‰
    df_matched = add_volume_data(df_matched, use_polygon=USE_POLYGON)
    
    # 5. å¤šç»´åº¦åˆ†æ
    print("\n" + "="*80)
    print("ğŸ“ˆ å¤šç»´åº¦èƒœç‡åˆ†æ")
    print("="*80 + "\n")
    
    dimensions = [
        ('dte', '1ï¸âƒ£  DTEï¼ˆåˆ°æœŸå¤©æ•°ï¼‰åˆ†æ', categorize_dte),
        ('otm_pct', '2ï¸âƒ£  OTMæ¯”ä¾‹åˆ†æ', categorize_otm),
        ('trade_hour', '3ï¸âƒ£  äº¤æ˜“æ—¶é—´æ®µåˆ†æ', categorize_time),
        ('share_eqv', '4ï¸âƒ£  æœŸæƒæµåŠ¨æ€§ï¼ˆShare_eqvï¼‰åˆ†æ', categorize_share_eqv),
    ]
    
    if USE_POLYGON:
        dimensions.append(('volume', '5ï¸âƒ£  ä¹°å…¥å½“æ—¥æˆäº¤é‡åˆ†æ', categorize_volume))
    
    results = {}
    
    for dim, title, categorize_func in dimensions:
        print(f"\n{title}")
        print("-" * 80)
        stats = analyze_by_dimension(df_matched, dim, categorize_func)
        print(stats)
        results[dim] = stats
    
    # 6. ç»¼åˆæ‘˜è¦
    print("\n" + "="*80)
    print("ğŸ“‹ ç»¼åˆæ‘˜è¦")
    print("="*80)
    
    total_trades = len(df_matched)
    total_wins = df_matched['win'].sum()
    overall_winrate = df_matched['win'].mean()
    total_pnl = df_matched['pnl'].sum()
    avg_pnl_pct = df_matched['pnl_pct'].mean()
    
    print(f"""
æ€»äº¤æ˜“æ•°: {total_trades}
æ€»èƒœåœº: {total_wins}
æ€»ä½“èƒœç‡: {overall_winrate:.1%}
æ€»ç›ˆäº: ${total_pnl:+,.2f}
å¹³å‡ç›ˆäº%: {avg_pnl_pct:+.2%}

æ•°æ®å®Œæ•´æ€§:
  - DTEæ•°æ®: {df_matched['dte'].notna().sum()}/{total_trades} ({df_matched['dte'].notna().mean():.1%})
  - OTMæ•°æ®: {df_matched['otm_pct'].notna().sum()}/{total_trades} ({df_matched['otm_pct'].notna().mean():.1%})
  - æ—¶é—´æ•°æ®: {df_matched['trade_hour'].notna().sum()}/{total_trades} ({df_matched['trade_hour'].notna().mean():.1%})
  - Share_eqvæ•°æ®: {df_matched['share_eqv'].notna().sum()}/{total_trades} ({df_matched['share_eqv'].notna().mean():.1%})
  - æˆäº¤é‡æ•°æ®: {df_matched['volume'].notna().sum()}/{total_trades} ({df_matched['volume'].notna().mean():.1%})
    """)
    
    # 7. ä¿å­˜è¯¦ç»†æ•°æ®
    output_file = 'winrate_analysis_detail.csv'
    df_matched.to_csv(output_file, index=False)
    print(f"\nâœ… è¯¦ç»†æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
    
    # 8. ä¿å­˜ç»Ÿè®¡æ‘˜è¦
    summary_file = 'winrate_analysis_summary.txt'
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write("å›æµ‹ç»“æœå¤šç»´åº¦èƒœç‡åˆ†ææ‘˜è¦\n")
        f.write("="*80 + "\n\n")
        
        for dim, title, _ in dimensions:
            f.write(f"\n{title}\n")
            f.write("-" * 80 + "\n")
            f.write(results[dim].to_string())
            f.write("\n")
    
    print(f"âœ… ç»Ÿè®¡æ‘˜è¦å·²ä¿å­˜åˆ°: {summary_file}")
    
    print("\n" + "="*80)
    print("âœ… åˆ†æå®Œæˆï¼")
    print("="*80 + "\n")

if __name__ == '__main__':
    main()

